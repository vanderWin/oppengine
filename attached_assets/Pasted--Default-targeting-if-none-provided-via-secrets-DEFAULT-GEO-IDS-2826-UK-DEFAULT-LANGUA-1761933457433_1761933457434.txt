# Default targeting if none provided via secrets
_DEFAULT_GEO_IDS = ["2826"]  # UK
_DEFAULT_LANGUAGE_ID = "1000"  # English

def get_gads_client_and_customer_id():
    """Prefer Streamlit Secrets; safely fall back to local google-ads.yaml.
    Returns (client, effective_customer_id) or (None, "").
    """
    try:
        from google.ads.googleads.client import GoogleAdsClient
    except Exception:
        st.error("google-ads library not installed. Run: pip install google-ads")
        return None, ""

    def _norm_id(s):
        return str(s).replace("-", "").strip() if s else ""

    try:
        has_secrets = "google_ads" in st.secrets
    except Exception:
        has_secrets = False

    if has_secrets:
        s = st.secrets["google_ads"]
        try:
            cfg = {
                "developer_token": s.get("developer_token"),
                "client_id": s.get("client_id"),
                "client_secret": s.get("client_secret"),
                "refresh_token": s.get("refresh_token"),
                "login_customer_id": _norm_id(s.get("login_customer_id")),
                "client_customer_id": _norm_id(s.get("client_customer_id")),
                "use_proto_plus": True,
            }
            cfg = {k: v for k, v in cfg.items() if v is not None}
            import yaml as _yaml
            yaml_text = _yaml.dump(cfg)
            client = GoogleAdsClient.load_from_string(yaml_text, version="v20")
            effective_id = _norm_id(s.get("client_customer_id")) or _norm_id(s.get("login_customer_id"))
            return client, effective_id
        except Exception as e:
            st.error(f"Failed to load Google Ads client from Streamlit secrets: {e}")
            return None, ""

    # Fallback: local yaml
    from pathlib import Path as _Path
    yaml_path = _Path(__file__).parent / "google-ads.yaml"
    if not yaml_path.exists():
        st.error("No Streamlit secrets and no local google-ads.yaml found.")
        return None, ""
    try:
        import yaml as _yaml
        with open(yaml_path, "r", encoding="utf-8") as f:
            cfg = _yaml.safe_load(f) or {}
        client = GoogleAdsClient.load_from_storage(str(yaml_path), version="v20")
        effective_id = _norm_id(cfg.get("client_customer_id")) or _norm_id(cfg.get("login_customer_id"))
        return client, effective_id
    except Exception as e:
        st.error(f"Failed to load Google Ads client from {yaml_path.name}: {e}")
        return None, ""

def _parse_geo_ids(s: str) -> list[str]:
    return [x.strip() for x in s.split(",") if x.strip()]

def fetch_historical_metrics_gads(client, customer_id: str, keywords: list[str],
                                  geo_ids: list[str], language_id: str,
                                  batch_size: int = 700) -> tuple[pd.DataFrame, list]:
    try:
        from google.protobuf.json_format import MessageToDict
    except Exception:
        MessageToDict = None

    googleads_service = client.get_service("GoogleAdsService")
    idea_service = client.get_service("KeywordPlanIdeaService")

    out_rows, raw_results = [], []
    total = len(keywords)
    prog = st.progress(0.0, text="Requesting batchesâ€¦")

    for i in range(0, total, batch_size):
        batch = keywords[i:i+batch_size]
        req = client.get_type("GenerateKeywordHistoricalMetricsRequest")
        req.customer_id = customer_id
        req.keywords.extend(batch)
        req.keyword_plan_network = client.enums.KeywordPlanNetworkEnum.GOOGLE_SEARCH
        req.language = googleads_service.language_constant_path(language_id)
        for gid in geo_ids:
            req.geo_target_constants.append(googleads_service.geo_target_constant_path(gid))

        resp = idea_service.generate_keyword_historical_metrics(request=req)

        if MessageToDict:
            raw_results.extend([MessageToDict(r._pb) for r in resp.results])
        else:
            for r in resp.results:
                raw_results.append({"text": getattr(r, "text", ""), "closeVariants": list(getattr(r, "close_variants", []))})

        for r in resp.results:
            m = r.keyword_metrics
            canonical = r.text.lower().strip()
            variants = [v.lower().strip() for v in (list(r.close_variants) if r.close_variants else [])]
            aliases = [canonical] + [v for v in variants if v]
            base = {
                "canonical_keyword": canonical,
                "aliases": aliases,
                "close_variants": ", ".join(variants) if variants else "",
                "avg_monthly_searches": int(m.avg_monthly_searches) if m.avg_monthly_searches is not None else None,
                "competition_index": int(m.competition_index) if m.competition_index is not None else None,
                "competition_level": m.competition.name if hasattr(m.competition, "name") else str(m.competition),
                "low_top_of_page_bid_micros": int(m.low_top_of_page_bid_micros) if m.low_top_of_page_bid_micros is not None else None,
                "high_top_of_page_bid_micros": int(m.high_top_of_page_bid_micros) if m.high_top_of_page_bid_micros is not None else None,
            }
            if getattr(m, "monthly_search_volumes", None):
                for mv in m.monthly_search_volumes:
                    month_num = [
                        "JANUARY","FEBRUARY","MARCH","APRIL","MAY","JUNE",
                        "JULY","AUGUST","SEPTEMBER","OCTOBER","NOVEMBER","DECEMBER"
                    ].index(mv.month.name)+1
                    out_rows.append(base | {
                        "year": int(mv.year),
                        "month": month_num,
                        "monthly_searches": int(mv.monthly_searches) if mv.monthly_searches is not None else None
                    })
            else:
                out_rows.append(base | {"year": None, "month": None, "monthly_searches": None})

        prog.progress(min((i+batch_size)/max(total,1),1.0))
